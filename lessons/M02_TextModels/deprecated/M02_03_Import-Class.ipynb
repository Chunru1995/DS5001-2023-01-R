{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "```\n",
    "Class:   DS 5001\n",
    "Module:  02 Lab\n",
    "Topic:   A Class for Importing a Text\n",
    "Author:  R.C. Alvarado\n",
    "Purpose: Create a class to wrap our functions and variables relating to parsing a raw text.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config \n",
    "\n",
    "We put everything we know about our text and its processing requirements in a configuration dictionary. This dictionary has to be structured in a predictable way. Ideally, it would be defined by a schema in a language like XML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'src_file': \"data_in/pg105.txt\",\n",
    "    'cruft': {\n",
    "        'start_line_pat': r\"\\*\\*\\*\\s*START OF (THE|THIS) PROJECT\",\n",
    "        'end_line_pat': 'End of the Project Gutenberg EBook'\n",
    "    }, \n",
    "    'ohco': {\n",
    "        'chapter': {\n",
    "            'pat': r\"^\\s*(chapter|letter)\\s+(\\d+)\",\n",
    "            'type': 'milestone'\n",
    "        },\n",
    "        'paragraph': {\n",
    "            'pat': r\"\\n\\n+\",\n",
    "            'type': 'delimitter'\n",
    "            \n",
    "        },\n",
    "        'sentence': {\n",
    "            'pat': r\"[.?!;:]+\",\n",
    "            'type': 'delimitter'\n",
    "        },\n",
    "        'token': {\n",
    "            'pat': r\"[\\s',-]+\",\n",
    "            'type': 'delimitter'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class TextImporter():\n",
    "    \n",
    "    src_imported:bool = False       \n",
    "    src_clipped:bool = False\n",
    "        \n",
    "    def __init__(self, config):\n",
    "        self.config:dict = config # Ideally, validate against a schema\n",
    "        self._validate_config()\n",
    "        self.OHCO:list = list(self.config['ohco'].keys())\n",
    "        \n",
    "    def _validate_config(self):\n",
    "        config_keys_ideal = {'src_file','cruft','ohco'}\n",
    "        config_keys_real = set(self.config.keys())\n",
    "        if config_keys_real != config_keys_ideal:\n",
    "            print(\"Config not valid\")\n",
    "\n",
    "    def import_source(self, strip:bool = True):\n",
    "        \"\"\"Convert a raw text file into a dataframe of lines\"\"\"\n",
    "        src_file = self.config['src_file']\n",
    "        self.src_df = pd.DataFrame({'line_str':open(src_file,'r').readlines()})\n",
    "        self.src_df.index.name = 'line_id'\n",
    "        if strip:\n",
    "            self.src_df.line_str = self.src_df.line_str.str.strip()\n",
    "        self.src_imported = True\n",
    "        self._clip_lines()\n",
    "        return self\n",
    "\n",
    "    def _clip_lines(self):\n",
    "        \"\"\"Remove cruft lines from beginning and/or end of file\"\"\"\n",
    "        start_pat = self.config['cruft']['start_line_pat']\n",
    "        end_pat = self.config['cruft']['end_line_pat']\n",
    "        start = self.src_df.line_str.str.match(start_pat)\n",
    "        end = self.src_df.line_str.str.match(end_pat)\n",
    "        start_line_num = self.src_df.loc[start].index[0]\n",
    "        end_line_num = self.src_df.loc[end].index[0]\n",
    "        self.src_df = self.src_df.loc[start_line_num + 1 : end_line_num - 2]\n",
    "        self.src_clipped == True\n",
    "        \n",
    "    def parse_tokens(self):\n",
    "        \"\"\"Convert lines to tokens with arbitrary OHCO\"\"\"\n",
    "        if self.src_imported:\n",
    "            self.tokens = self.src_df.copy()\n",
    "            for i, level in enumerate(self.config['ohco']):\n",
    "                if self.config['ohco'][level]['type'] == 'milestone':\n",
    "                    self.tokens = self._group_by_milestone(self.tokens, i)\n",
    "                elif self.config['ohco'][level]['type'] == 'delimitter':\n",
    "                    self.tokens = self._split_by_delimitter(self.tokens, i)\n",
    "                else:\n",
    "                    raise(\"No method for level\")\n",
    "            return self\n",
    "        else:\n",
    "            print(\"Source not imported. Please run .import_source()\")\n",
    "\n",
    "    def _group_by_milestone(self, df, ohco_level, \n",
    "                           src_col='line_str', \n",
    "                           tmp_col='div_idx', \n",
    "                           id_suffix='_id', \n",
    "                           case=False):\n",
    "        \"\"\"Group and chunk text by milestone,such as chapter headers\"\"\"\n",
    "        div_name = self.OHCO[ohco_level]\n",
    "        div_pat = self.config['ohco'][div_name]['pat']\n",
    "        div_lines = df[src_col].str.match(div_pat, case=case)\n",
    "        df.loc[div_lines, div_name] = [i+1 for i in range(df.loc[div_lines].shape[0])]\n",
    "        df[div_name] = df[div_name].ffill()\n",
    "        df = df.loc[~df[div_name].isna()] # Remove everything before first div\n",
    "        df = df.loc[~div_lines] # Remove milestone markers\n",
    "        df[div_name] = df[div_name].astype('int')\n",
    "        df = df.groupby(self.OHCO[:ohco_level+1])[src_col].apply(lambda x: '\\n'.join(x)).to_frame() # Make big string\n",
    "        df[src_col] = df[src_col].str.strip()    \n",
    "        df = df.rename(columns={src_col:'{}_str'.format(div_name)})\n",
    "        df.index.name = \"{}_id\".format(div_name)\n",
    "        return df\n",
    "\n",
    "    def _split_by_delimitter(self, df, ohco_level, \n",
    "                            src_col_suffix='_str', \n",
    "                            join_pat='\\n', \n",
    "                            id_suffix='_num', \n",
    "                            case=False):\n",
    "        \"\"\"Split and chunk text by a delimmitter, for paragraphs, sentences, and tokens\"\"\"\n",
    "\n",
    "        OHCO = list(config['ohco'].keys())\n",
    "        div_name = OHCO[ohco_level]\n",
    "        div_pat = config['ohco'][div_name]['pat']\n",
    "        src_div_name = OHCO[ohco_level-1]\n",
    "        src_col = f\"{src_div_name}{src_col_suffix}\"\n",
    "        df2 = df[src_col].str.split(div_pat, expand=True).stack().to_frame()\\\n",
    "            .rename(columns={0:div_name}).copy()\n",
    "        df2.index.names = df.index.names + [div_name + id_suffix]\n",
    "        df2[div_name] = df2[div_name].str.replace(join_pat, ' ')\n",
    "        df2 = df2[~df2[div_name].str.match(r'^\\s*$')]    \n",
    "        df2 = df2.rename(columns={div_name:f'{div_name}_str'})\n",
    "        return df2        \n",
    "\n",
    "    def gather_tokens(self, level=0, collapse=False):\n",
    "        \"\"\"Gather tokens into strings for arbitrary OHCO level\"\"\"\n",
    "        max_level = len(self.OHCO) - 2\n",
    "        if level > max_level:\n",
    "            print(f\"Level {level} too high. Try between 0 and {max_level}\")\n",
    "        else:\n",
    "            level_name = self.OHCO[level]\n",
    "            idx = self.tokens.index.names[:level+1]\n",
    "            return self.tokens.groupby(idx).token_str.apply(lambda x: ' '.join(x)).to_frame(f'{level_name}_str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TextImporter(config).import_source().parse_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chapter_id</th>\n",
       "      <th>paragraph_num</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kellynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">11</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th>34</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>its</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>importance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>Finis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84893 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  token_str\n",
       "chapter_id paragraph_num sentence_num token_num            \n",
       "1          0             0            0                 Sir\n",
       "                                      1              Walter\n",
       "                                      2              Elliot\n",
       "                                      3                  of\n",
       "                                      4            Kellynch\n",
       "...                                                     ...\n",
       "24         11            6            34                 in\n",
       "                                      35                its\n",
       "                                      36           national\n",
       "                                      37         importance\n",
       "           12            0            0               Finis\n",
       "\n",
       "[84893 rows x 1 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TI.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = 'bar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey bar\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hey {foo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "TI.gather_tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eta",
   "language": "python",
   "name": "eta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
